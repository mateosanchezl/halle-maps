{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = os.listdir(path='../weather_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = ['./' + filename for filename in csv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files.remove('./weather_preprocessing.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./eastbournedata.csv appended\n",
      "./southamptondata.csv appended\n",
      "./dunstaffnagedata.csv appended\n",
      "Couldn't append ./.DS_Store: 'utf-8' codec can't decode byte 0xb8 in position 559: invalid start byte\n",
      "./aberporthdata.csv appended\n",
      "./paisleydata.csv appended\n",
      "./durhamdata.csv appended\n",
      "./braemardata.csv appended\n",
      "./stornowaydata.csv appended\n",
      "./heathrowdata.csv appended\n",
      "./chivenordata.csv appended\n",
      "./manstondata.csv appended\n",
      "./eskdalemuirdata.csv appended\n",
      "./newtonriggdata.csv appended\n",
      "./shawburydata.csv appended\n",
      "./yeoviltondata.csv appended\n",
      "./ballypatrickdata.csv appended\n",
      "./suttonboningtondata.csv appended\n",
      "./leucharsdata.csv appended\n",
      "./ringwaydata.csv appended\n",
      "./bradforddata.csv appended\n",
      "./nairndata.csv appended\n",
      "./wickairportdata.csv appended\n",
      "./cwmystwythdata.csv appended\n",
      "./cambornedata.csv appended\n",
      "./hurndata.csv appended\n",
      "./tireedata.csv appended\n",
      "./valleydata.csv appended\n",
      "./lowestoftdata.csv appended\n",
      "./whitbydata.csv appended\n",
      "./sheffielddata.csv appended\n",
      "./armaghdata.csv appended\n",
      "./lerwickdata.csv appended\n",
      "./cambridgedata.csv appended\n",
      "./oxforddata.csv appended\n",
      "./waddingtondata.csv appended\n",
      "./rossonwyedata.csv appended\n",
      "     yyyy   mm  tmax  tmin latitude  longitude    location yyyy \n",
      "0     NaN  NaN  degC  degC    0.285     50.759  eastbourne   NaN\n",
      "1  1959.0  1.0   6.4   1.1    0.285     50.759  eastbourne   NaN\n",
      "2  1959.0  2.0   6.6     2    0.285     50.759  eastbourne   NaN\n",
      "3  1959.0  3.0  10.4   5.1    0.285     50.759  eastbourne   NaN\n",
      "4  1959.0  4.0  12.7   7.3    0.285     50.759  eastbourne   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_files(csv_files):\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            # Extract location name from filename\n",
    "            location = os.path.basename(file).replace('data.csv', '')\n",
    "            \n",
    "            # Read CSV file, assuming the lat and lon are in the first row of the respective columns\n",
    "            df = pd.read_csv(file)\n",
    "            if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "                latitude = df.at[0, 'latitude']\n",
    "                longitude = df.at[0, 'longitude']\n",
    "                df['latitude'].fillna(latitude, inplace=True)  # Fill all NaN latitudes\n",
    "                df['longitude'].fillna(longitude, inplace=True)  # Fill all NaN longitudes\n",
    "            else:\n",
    "                # Assumes latitude and longitude are the last columns if not explicitly named\n",
    "                latitude = df.iloc[0, -2]\n",
    "                longitude = df.iloc[0, -1]\n",
    "                df.iloc[:, -2].fillna(latitude, inplace=True)\n",
    "                df.iloc[:, -1].fillna(longitude, inplace=True)\n",
    "\n",
    "            df['location'] = location  # Add location name as a new column\n",
    "            dfs.append(df)\n",
    "            print(f\"{file} appended\")\n",
    "        except Exception as e:\n",
    "            print(f\"Couldn't append {file}: {e}\")\n",
    "    \n",
    "    # Combine all dataframes into one\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "combined_df = process_files(csv_files)\n",
    "print(combined_df.head())  # To verify output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38777 entries, 0 to 38776\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   yyyy       37742 non-null  object \n",
      " 1   mm         38741 non-null  object \n",
      " 2   tmax       38774 non-null  object \n",
      " 3   tmin       37775 non-null  object \n",
      " 4   latitude   38777 non-null  object \n",
      " 5   longitude  38777 non-null  float64\n",
      " 6   location   38777 non-null  object \n",
      " 7   yyyy       999 non-null    object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.iloc[:, :7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows that have NaN values in any column\n",
    "cleaned_df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      yyyy    mm  tmax  tmin latitude  longitude    location\n",
       "1   1959.0   1.0   6.4   1.1    0.285     50.759  eastbourne\n",
       "2   1959.0   2.0   6.6     2    0.285     50.759  eastbourne\n",
       "3   1959.0   3.0  10.4   5.1    0.285     50.759  eastbourne\n",
       "4   1959.0   4.0  12.7   7.3    0.285     50.759  eastbourne\n",
       "5   1959.0   5.0  16.8   9.3    0.285     50.759  eastbourne\n",
       "6   1959.0   6.0  18.9  11.9    0.285     50.759  eastbourne\n",
       "7   1959.0   7.0  21.6  14.2    0.285     50.759  eastbourne\n",
       "8   1959.0   8.0  21.8  14.8    0.285     50.759  eastbourne\n",
       "9   1959.0   9.0  20.8  12.8    0.285     50.759  eastbourne\n",
       "10  1959.0  10.0  16.8  10.7    0.285     50.759  eastbourne"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '20-Jan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert year and month to integer if they are floats and contain no decimal\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cleaned_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myyyy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cleaned_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myyyy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      3\u001b[0m cleaned_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cleaned_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmm\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Display data types to confirm changes\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    416\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    417\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    418\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    419\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[1;32m    420\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '20-Jan'"
     ]
    }
   ],
   "source": [
    "# Convert year and month to integer if they are floats and contain no decimal\n",
    "cleaned_df['yyyy'] = cleaned_df['yyyy'].astype(int)\n",
    "cleaned_df['mm'] = cleaned_df['mm'].astype(int)\n",
    "\n",
    "# Display data types to confirm changes\n",
    "cleaned_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique years: [1959.0 1960.0 1961.0 1962.0 1963.0 1964.0 1965.0 1966.0 1967.0 1968.0\n",
      " 1969.0 1970.0 1971.0 1972.0 1973.0 1974.0 1975.0 1976.0 1977.0 1978.0\n",
      " 1979.0 1980.0 1981.0 1982.0 1983.0 1984.0 1985.0 1986.0 1987.0 1988.0\n",
      " 1989.0 1990.0 1991.0 1992.0 1993.0 1994.0 1995.0 1996.0 1997.0 1998.0\n",
      " 1999.0 2000.0 2001.0 2002.0 2003.0 2004.0 2005.0 2006.0 2007.0 2008.0\n",
      " 2009.0 2010.0 2011.0 2012.0 2013.0 2014.0 2015.0 2016.0 2017.0 2018.0\n",
      " 2019.0 2020.0 2021.0 2022.0 2023.0 2024.0 nan '1855' '1856' '1857' '1858'\n",
      " '1859' '1860' '1861' '1862' '1863' '1864' '1865' '1866' '1867' '1868'\n",
      " '1869' '1870' '1871' '1872' '1873' '1874' '1875' '1876' '1877' '1878'\n",
      " '1879' '1880' '1881' '1882' '1883' '1884' '1885' '1886' '1887' '1888'\n",
      " '1889' '1890' '1891' '1892' '1893' '1894' '1895' '1896' '1897' '1898'\n",
      " '1899' '1900' '1901' '1902' '1903' '1904' '1905' '1906' '1907' '1908'\n",
      " '1909' '1910' '1911' '1912' '1913' '1914' '1915' '1916' '1917' '1918'\n",
      " '1919' '1920' '1921' '1922' '1923' '1924' '1925' '1926' '1927' '1928'\n",
      " '1929' '1930' '1931' '1932' '1933' '1934' '1935' '1936' '1937' '1938'\n",
      " '1939' '1940' '1941' '1942' '1943' '1944' '1945' '1946' '1947' '1948'\n",
      " '1949' '1950' '1951' '1952' '1953' '1954' '1955' '1956' '1957' '1958'\n",
      " '1959' '1960' '1961' '1962' '1963' '1964' '1965' '1966' '1967' '1968'\n",
      " '1969' '1970' '1971' '1972' '1973' '1974' '1975' '1976' '1977' '1978'\n",
      " '1979' '1980' '1981' '1982' '1983' '1984' '1985' '1986' '1987' '1988'\n",
      " '1989' '1990' '1991' '1992' '1993' '1994' '1995' '1996' '1997' '1998'\n",
      " '1999' '2000' 'Site Clo' 1880.0 1881.0 1882.0 1883.0 1884.0 1885.0 1886.0\n",
      " 1887.0 1888.0 1889.0 1890.0 1891.0 1892.0 1893.0 1894.0 1895.0 1896.0\n",
      " 1897.0 1898.0 1899.0 1900.0 1901.0 1902.0 1903.0 1904.0 1905.0 1906.0\n",
      " 1907.0 1908.0 1909.0 1910.0 1911.0 1912.0 1913.0 1914.0 1915.0 1916.0\n",
      " 1917.0 1918.0 1919.0 1920.0 1921.0 1922.0 1923.0 1924.0 1925.0 1926.0\n",
      " 1927.0 1928.0 1929.0 1930.0 1931.0 1932.0 1933.0 1934.0 1935.0 1936.0\n",
      " 1937.0 1938.0 1939.0 1940.0 1941.0 1942.0 1943.0 1944.0 1945.0 1946.0\n",
      " 1947.0 1948.0 1949.0 1950.0 1951.0 1952.0 1953.0 1954.0 1955.0 1956.0\n",
      " 1957.0 1958.0 1873.0 1874.0 1875.0 1876.0 1877.0 1878.0 1879.0 '20-Jan'\n",
      " '20-Feb' '20-Mar' '20-Apr' '20-May' '20-Jun' '20-Jul' '20-Aug' '20-Sep'\n",
      " '20-Oct' '20-Nov' '20-Dec' '2013' '2014' '2015' '2016' '2017' '2018'\n",
      " '2019' '2020' '2021' '2022' '2023' '2024' '2001' '2002' '2003' '2004'\n",
      " 'Site Cl' '2005' '2006' '2007' '2008' '2009' '2010' '2011' 'Site clo'\n",
      " '1853' '1854' 'Jan-19' 'Feb-19' 'Mar-19' 'Apr-19' 'May-19' 'Jun-19'\n",
      " 'Jul-19' 'Aug-19' 'Sep-19' 'Oct-19' 'Nov-19' 'Dec-19' 'Jan-20' 'Feb-20'\n",
      " 'Mar-20' 'Apr-20' 'May-20' 'Jun-20' 'Jul-20' 'Aug-20' 'Sep-20' 'Oct-20'\n",
      " 'Nov-20' 'Dec-20' 1853.0 1854.0 1855.0 1856.0 1857.0 1858.0 1859.0 1860.0\n",
      " 1861.0 1862.0 1863.0 1864.0 1865.0 1866.0 1867.0 1868.0 1869.0 1870.0\n",
      " 1871.0 1872.0]\n",
      "Unique months: [1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 nan '1' '2' '3' '4'\n",
      " '5' '6' '7' '8' '9' '10' '11' '12' 'sed' '---' '5.8' '4.2' '9.7' '13.1'\n",
      " '14' '16.2' '17.4' '18.7' '16.4' '9.2' '9.6' '8.2' '8.9' '10.2' '13'\n",
      " '14.1' '15.9' '18.6' '18.1' '15.8' '13.6' '6.9' '6.5' '8.6' '12.7' '13.8'\n",
      " '15.4' '18.2' '19.7' '15.7' '12.1' '9.5' '7.7' '4.5' '10.4' '13.3' '14.3'\n",
      " '16.5' '17.1' '15.2' '10.7' '8.7' '12.8' '14.6' '16.3' '7.2' '13.9' '17'\n",
      " '21.4' '17.5' '14.2' '10.1' '7.4' '13.5' '11.4' '14.7' '16.9' '11.5'\n",
      " '8.5' '13.4' '19.9' '19' '19.5' '7.3' '8.3' '10.8' '10.3' '17.9' '15.3'\n",
      " '12.9' '9.1' '4.7' '6.7' '6.4' '12.5' '18.3' '6.2' '9.4' '12.3' '7.8'\n",
      " '6.8' '9.8' '17.2' '11.2' '6.3' '11.3' '16.1' '6.1' '4.6' '11.9' '12.6'\n",
      " '19.2' '21.3' '7.1' '3.4' '10.6' '14.5' '15' '17.6' '12.2' '17.7' '8.4'\n",
      " '7.6' '16' '8.8' '15.5' '17.3' '19.1' '19.6' '10.5' '7.9' '10.9' '18'\n",
      " '12.4' '16.7' '1.3' '3.3' '11.1' '15.6' '5.6' '15.1' '8.1' '9.3' '16.8'\n",
      " '5.5' '7.5' '18.5' '6.6' '16.6' '17.8' '18.4' '14.9' '9.9' '19.3' '18.9'\n",
      " '20.4' '5.9' '13.7' '14.4' '11.6' '11.8' '5.3' '20.7' '13.2' '2.3' '20.1'\n",
      " '19.8' '5.4' '18.8' '21.1' '22.4' '20.2' '14.8' '11.7' '21.2' '5.1'\n",
      " '20.3' '19.4' '20.6' 'osed']\n"
     ]
    }
   ],
   "source": [
    "# Display unique values in the 'yyyy' and 'mm' columns\n",
    "print(\"Unique years:\", df['yyyy'].unique())\n",
    "print(\"Unique months:\", df['mm'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/7x67cwrs4s1b0c_c97sg5kt00000gn/T/ipykernel_39348/1839224974.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['yyyy'] = cleaned_df['yyyy'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Convert all entries in 'yyyy' to string\n",
    "cleaned_df['yyyy'] = cleaned_df['yyyy'].astype(str)\n",
    "\n",
    "# Remove known erroneous entries\n",
    "cleaned_df = cleaned_df[~cleaned_df['yyyy'].str.contains('Site|osed', na=False)]\n",
    "\n",
    "# Convert valid year strings back to integers\n",
    "cleaned_df['yyyy'] = pd.to_numeric(cleaned_df['yyyy'], errors='coerce')\n",
    "cleaned_df.dropna(subset=['yyyy'], inplace=True)  # Drop rows where 'yyyy' could not be converted\n",
    "cleaned_df['yyyy'] = cleaned_df['yyyy'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1959</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1959</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.285</td>\n",
       "      <td>50.759</td>\n",
       "      <td>eastbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38772</th>\n",
       "      <td>2023</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.584</td>\n",
       "      <td>51.911</td>\n",
       "      <td>rossonwye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38773</th>\n",
       "      <td>2023</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>-2.584</td>\n",
       "      <td>51.911</td>\n",
       "      <td>rossonwye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38774</th>\n",
       "      <td>2024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-2.584</td>\n",
       "      <td>51.911</td>\n",
       "      <td>rossonwye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38775</th>\n",
       "      <td>2024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-2.584</td>\n",
       "      <td>51.911</td>\n",
       "      <td>rossonwye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38776</th>\n",
       "      <td>2024</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-2.584</td>\n",
       "      <td>51.911</td>\n",
       "      <td>rossonwye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37163 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       yyyy    mm  tmax tmin latitude  longitude    location\n",
       "1      1959   1.0   6.4  1.1    0.285     50.759  eastbourne\n",
       "2      1959   2.0   6.6    2    0.285     50.759  eastbourne\n",
       "3      1959   3.0  10.4  5.1    0.285     50.759  eastbourne\n",
       "4      1959   4.0  12.7  7.3    0.285     50.759  eastbourne\n",
       "5      1959   5.0  16.8  9.3    0.285     50.759  eastbourne\n",
       "...     ...   ...   ...  ...      ...        ...         ...\n",
       "38772  2023  11.0  11.4    5   -2.584     51.911   rossonwye\n",
       "38773  2023  12.0  10.5  5.9   -2.584     51.911   rossonwye\n",
       "38774  2024   1.0   8.3  2.3   -2.584     51.911   rossonwye\n",
       "38775  2024   2.0  11.3  5.3   -2.584     51.911   rossonwye\n",
       "38776  2024   3.0    12  4.9   -2.584     51.911   rossonwye\n",
       "\n",
       "[37163 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from possible month formats to integers\n",
    "month_mapping = {\n",
    "    '1': 1, '01': 1, 'Jan': 1, 'Jan-19': 1, 'January': 1, '20-Jan': 1,\n",
    "    '2': 2, '02': 2, 'Feb': 2, 'Feb-19': 2, 'February': 2, '20-Feb': 2,\n",
    "    '3': 3, '03': 3, 'Mar': 3, 'Mar-19': 3, 'March': 3, '20-Mar': 3,\n",
    "    '4': 4, '04': 4, 'Apr': 4, 'Apr-19': 4, 'April': 4, '20-Apr': 4,\n",
    "    '5': 5, '05': 5, 'May': 5, 'May-19': 5, '20-May': 5,\n",
    "    '6': 6, '06': 6, 'Jun': 6, 'Jun-19': 6, 'June': 6, '20-Jun': 6,\n",
    "    '7': 7, '07': 7, 'Jul': 7, 'Jul-19': 7, 'July': 7, '20-Jul': 7,\n",
    "    '8': 8, '08': 8, 'Aug': 8, 'Aug-19': 8, 'August': 8, '20-Aug': 8,\n",
    "    '9': 9, '09': 9, 'Sep': 9, 'Sep-19': 9, 'September': 9, '20-Sep': 9,\n",
    "    '10': 10, 'Oct': 10, 'Oct-19': 10, 'October': 10, '20-Oct': 10,\n",
    "    '11': 11, 'Nov': 11, 'Nov-19': 11, 'November': 11, '20-Nov': 11,\n",
    "    '12': 12, 'Dec': 12, 'Dec-19': 12, 'December': 12, '20-Dec': 12\n",
    "}\n",
    "\n",
    "# Replace all month representations with their numerical equivalents\n",
    "cleaned_df['mm'] = cleaned_df['mm'].replace(month_mapping).astype(str)\n",
    "\n",
    "# Convert to numeric, coercing errors and dropping NaN values\n",
    "cleaned_df['mm'] = pd.to_numeric(cleaned_df['mm'], errors='coerce')\n",
    "cleaned_df.dropna(subset=['mm'], inplace=True)\n",
    "cleaned_df['mm'] = cleaned_df['mm'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   yyyy  mm  tmax tmin latitude  longitude    location\n",
      "1  1959   1   6.4  1.1    0.285     50.759  eastbourne\n",
      "2  1959   2   6.6    2    0.285     50.759  eastbourne\n",
      "3  1959   3  10.4  5.1    0.285     50.759  eastbourne\n",
      "4  1959   4  12.7  7.3    0.285     50.759  eastbourne\n",
      "5  1959   5  16.8  9.3    0.285     50.759  eastbourne\n",
      "Unique years: [1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "Unique months: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.head())\n",
    "print(\"Unique years:\", sorted(cleaned_df['yyyy'].unique()))\n",
    "print(\"Unique months:\", sorted(cleaned_df['mm'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    # Convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    return c * r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Tmax: 18.9 °C, Tmin: 11.9 °C\n"
     ]
    }
   ],
   "source": [
    "def predict_temperature(year, month, lat, lon, df):\n",
    "    # Calculate distances using the Haversine formula\n",
    "    df['distance'] = df.apply(lambda row: haversine(lon, lat, row['longitude'], row['latitude']), axis=1)\n",
    "    \n",
    "    # Find the closest data point based on the calculated distance\n",
    "    closest_data = df[(df['yyyy'] == year) & (df['mm'] == month)].sort_values('distance').iloc[0]\n",
    "    \n",
    "    return closest_data['tmax'], closest_data['tmin']\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    tmax, tmin = predict_temperature(1959, 6, 0.285, 50.759, cleaned_df)\n",
    "    print(f\"Predicted Tmax: {tmax} °C, Tmin: {tmin} °C\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude      object\n",
      "longitude    float64\n",
      "dtype: object\n",
      "latitude     783\n",
      "longitude      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df[['latitude', 'longitude']].dtypes)  # Check current data types\n",
    "\n",
    "# Convert latitude and longitude to float if they are not already\n",
    "cleaned_df['latitude'] = pd.to_numeric(cleaned_df['latitude'], errors='coerce')\n",
    "cleaned_df['longitude'] = pd.to_numeric(cleaned_df['longitude'], errors='coerce')\n",
    "\n",
    "# Check for NaNs which indicate conversion failures\n",
    "print(cleaned_df[['latitude', 'longitude']].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv('model_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
